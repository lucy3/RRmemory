var idealLearner = Infer({method: "enumerate"}, function(){
  var p = uniformDraw([0.1,0.3, 0.5, 0.7,0.9])
  observe(Bernoulli({p: p}), true);
  observe(Bernoulli({p: p}), true);
  return p
})


var model1a = Infer({method: "enumerate"}, function(){
  var p = uniformDraw([0.1,0.3, 0.5, 0.7,0.9])
  observe(Bernoulli({p: p}), true); // change this to observing a sequence of bits
  return p
})

// translate the following code, into something more like: pay $1, retain perfect p, otherwise: noisy version
// resource rational part
var remembered_model1a =  Infer({method: "enumerate"}, function(){
  var noisify = function(p){  // the more you pay, the less noise you get 
    return flip(0.2) ? uniformDraw([0.1,0.3, 0.5, 0.7,0.9]) : p
  }
  var p = sample(model1a);
  var remembered_p = noisify(p)
  return remembered_p
})

// and then, translate the following into: if you get it "right", get $2
var model1b = Infer({method: "enumerate"}, function(){
  var p = sample(remembered_model1a);
  observe(Bernoulli({p: p}), true); // change this to observing a sequence of bits
  return p // write scoring function, get reward based off of that 
})
display(expectation(idealLearner))

display(expectation(model1a))
display(expectation(remembered_model1a))
display(expectation(model1b))
